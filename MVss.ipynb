{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-21T12:03:23.167698Z",
     "start_time": "2025-02-21T12:03:16.061814Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01malbumentations\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mA\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01malbumentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ToTensorV2\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# 自定义数据集类（修改为生成掩码）\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\New\\lib\\site-packages\\albumentations\\__init__.py:18\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcontextlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m suppress\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01malbumentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcheck_version\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m check_for_updates\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maugmentations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomposition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mserialization\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\New\\lib\\site-packages\\albumentations\\augmentations\\__init__.py:23\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms3d\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\New\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:37\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01malbucore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     14\u001B[0m     MAX_VALUES_BY_DTYPE,\n\u001B[0;32m     15\u001B[0m     NUM_MULTI_CHANNEL_DIMENSIONS,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     26\u001B[0m     to_float,\n\u001B[0;32m     27\u001B[0m )\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     29\u001B[0m     AfterValidator,\n\u001B[0;32m     30\u001B[0m     BaseModel,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     35\u001B[0m     model_validator,\n\u001B[0;32m     36\u001B[0m )\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m special\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping_extensions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Literal, Self, TypedDict\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01malbumentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maugmentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdropout\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mfdropout\u001B[39;00m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1055\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[1;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\New\\lib\\site-packages\\scipy\\__init__.py:134\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(name):\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m submodules:\n\u001B[1;32m--> 134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_importlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mscipy.\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mname\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    136\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\New\\lib\\importlib\\__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    125\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\New\\lib\\site-packages\\scipy\\special\\__init__.py:777\u001B[0m\n\u001B[0;32m    773\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_sf_error\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SpecialFunctionWarning, SpecialFunctionError\n\u001B[1;32m--> 777\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _ufuncs\n\u001B[0;32m    778\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_ufuncs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m    780\u001B[0m \u001B[38;5;66;03m# Replace some function definitions from _ufuncs to add Array API support\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\New\\lib\\site-packages\\scipy\\special\\_ufuncs.pyx:1\u001B[0m, in \u001B[0;36minit scipy.special._ufuncs\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torchvision.ops import box_iou\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from mvssnet import get_mvss  # 假设mvssnet.py包含提供的MVSS代码\n",
    "\n",
    "\n",
    "# 新增：掩码转边界框函数\n",
    "def mask_to_boxes(mask, threshold=0.5, min_area=10):\n",
    "    \"\"\"\n",
    "    将分割mask转换为边界框列表\n",
    "    mask: (H, W)的numpy数组，值在0-1之间\n",
    "    返回: list of [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    binary_mask = (mask > threshold).astype(np.uint8) * 255\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    boxes = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        boxes.append([x, y, x + w, y + h])\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "class DocumentTamperDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotation_path, DEBUG_SUBSET_SIZE, target_size=(512, 512),transforms=None, debug_mode=False):\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        with open(annotation_path) as f:\n",
    "            self.annotations = json.load(f)\n",
    "\n",
    "        if debug_mode:\n",
    "            self.annotations = self.annotations[:DEBUG_SUBSET_SIZE]\n",
    "\n",
    "        self.id_to_anns = {item['id']: item['region'] for item in self.annotations}\n",
    "        self.ids = list(self.id_to_anns.keys())\n",
    "        self.target_size = target_size  # 新增目标尺寸参数\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_id)\n",
    "\n",
    "        # 加载原始图像并获取尺寸\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        original_width, original_height = img.size\n",
    "\n",
    "        # 转换到目标尺寸\n",
    "        transform = get_transform(targer_size=self.target_size,train=self.transforms is not None)\n",
    "        img = transform(img)  # 应用包含Resize的transform\n",
    "\n",
    "        # 计算缩放比例\n",
    "        scale_w = self.target_size[0] / original_width\n",
    "        scale_h = self.target_size[1] / original_height\n",
    "\n",
    "        # 生成调整后的掩码\n",
    "        mask = np.zeros(self.target_size[::-1], dtype=np.float32)  # (H,W)\n",
    "        regions = self.id_to_anns[img_id]\n",
    "\n",
    "        for region in regions:\n",
    "            # 调整坐标到目标尺寸\n",
    "            xmin = int(float(region[0]) * scale_w)\n",
    "            ymin = int(float(region[1]) * scale_h)\n",
    "            xmax = int(float(region[2]) * scale_w)\n",
    "            ymax = int(float(region[3]) * scale_h)\n",
    "\n",
    "            # 确保坐标有效性\n",
    "            xmin = max(0, xmin)\n",
    "            ymin = max(0, ymin)\n",
    "            xmax = min(self.target_size[0], xmax)\n",
    "            ymax = min(self.target_size[1], ymax)\n",
    "\n",
    "            if xmax > xmin and ymax > ymin:\n",
    "                mask[ymin:ymax, xmin:xmax] = 1.0\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        # 生成调整后的边界框（可选）\n",
    "        boxes = []\n",
    "\n",
    "        # 应用数据增强\n",
    "        return img, {\n",
    "            \"masks\": mask,\n",
    "            \"boxes\": torch.zeros((0, 4), dtype=torch.float32),  # 示例保留结构\n",
    "            \"image_id\": torch.tensor([idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n",
    "# 修改后的数据转换函数（包含归一化）\n",
    "def get_transform(targer_size=(512, 512),train=True):\n",
    "    transforms = []\n",
    "    transforms.append(torchvision.transforms.Resize(targer_size))\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    transforms.append(torchvision.transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]))\n",
    "\n",
    "    if train:\n",
    "        transforms.append(torchvision.transforms.RandomHorizontalFlip(0.5))\n",
    "    return torchvision.transforms.Compose(transforms)\n",
    "\n",
    "\n",
    "# 修改模型创建函数\n",
    "def create_model(num_classes=1):\n",
    "    model = get_mvss(nclass=num_classes, sobel=True, constrain=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 修改后的训练函数\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch} Training\", leave=True)\n",
    "\n",
    "    for images, targets in progress_bar:\n",
    "        try:\n",
    "            images = torch.stack([img.to(device) for img in images])\n",
    "            masks = torch.stack([t['masks'].to(device) for t in targets])\n",
    "        except RuntimeError as e:\n",
    "            print(\"\\n尺寸不一致错误详情：\")\n",
    "            for i, t in enumerate(targets):\n",
    "                print(f\"样本 {i} 掩码尺寸：{t['masks'].shape}\")\n",
    "            raise\n",
    "        # MVSS网络前向传播\n",
    "        _, outputs = model(images)\n",
    "        loss = criterion(outputs, masks.unsqueeze(1))  # 添加通道维度\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def calculate_metrics(pred_boxes, true_boxes, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    计算单个样本的TP、FP、FN\n",
    "    \"\"\"\n",
    "    if len(pred_boxes) == 0:\n",
    "        return 0, 0, len(true_boxes)\n",
    "\n",
    "    if len(true_boxes) == 0:\n",
    "        return 0, len(pred_boxes), 0\n",
    "\n",
    "    # 计算IoU矩阵\n",
    "    iou_matrix = box_iou(pred_boxes, true_boxes)\n",
    "\n",
    "    # 找到最佳匹配（每个真实框最多匹配一个预测框）\n",
    "    matched_true = set()\n",
    "    matched_pred = set()\n",
    "\n",
    "    # 先为每个真实框找最佳预测\n",
    "    for true_idx in range(len(true_boxes)):\n",
    "        best_iou = iou_threshold\n",
    "        best_pred = -1\n",
    "        for pred_idx in range(len(pred_boxes)):\n",
    "            iou = iou_matrix[pred_idx, true_idx]\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_pred = pred_idx\n",
    "        if best_pred != -1 and best_pred not in matched_pred:\n",
    "            matched_true.add(true_idx)\n",
    "            matched_pred.add(best_pred)\n",
    "\n",
    "    tp = len(matched_true)\n",
    "    fp = len(pred_boxes) - len(matched_pred)\n",
    "    fn = len(true_boxes) - len(matched_true)\n",
    "\n",
    "    return tp, fp, fn\n",
    "\n",
    "\n",
    "# 修改后的验证函数\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=\"Validating\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in progress_bar:\n",
    "            images = torch.stack([img.to(device) for img in images])\n",
    "            _, outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "            for i in range(preds.shape[0]):\n",
    "                pred_mask = preds[i, 0]  # 获取单通道预测结果\n",
    "                h, w = targets[i]['masks'].shape[-2:]\n",
    "\n",
    "                # 调整预测掩码到原始尺寸\n",
    "                pred_mask = cv2.resize(pred_mask, (w, h))\n",
    "                pred_boxes = mask_to_boxes(pred_mask)\n",
    "                true_boxes = targets[i]['boxes'].cpu()\n",
    "\n",
    "                # 转换并计算指标\n",
    "                pred_boxes = torch.as_tensor(pred_boxes, dtype=torch.float32) if pred_boxes else torch.zeros((0, 4))\n",
    "                tp, fp, fn = calculate_metrics(pred_boxes, true_boxes)\n",
    "\n",
    "                total_tp += tp\n",
    "                total_fp += fp\n",
    "                total_fn += fn\n",
    "\n",
    "    precision = total_tp / (total_tp + total_fp + 1e-10)\n",
    "    recall = total_tp / (total_tp + total_fn + 1e-10)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "    return {\n",
    "        \"Micro_Prec\": float(precision),\n",
    "        \"Micro_Recall\": float(recall),\n",
    "        \"Micro_F1\": float(f1)\n",
    "    }\n",
    "\n",
    "\n",
    "# 在main函数中需要调整优化器设置（因为模型参数结构变化）\n",
    "def main():\n",
    "    # 超参数配置\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_EPOCHS = 15\n",
    "    LR = 0.005\n",
    "    VAL_SPLIT = 0.2\n",
    "    DEBUG_MODE = True\n",
    "    DEBUG_SUBSET_SIZE = 10\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 数据集加载\n",
    "    full_dataset = DocumentTamperDataset(\n",
    "        image_dir=\"train/images\",\n",
    "        annotation_path=\"train/label_train.json\",\n",
    "        DEBUG_SUBSET_SIZE=DEBUG_SUBSET_SIZE,\n",
    "        transforms=get_transform(train=True),\n",
    "        debug_mode=DEBUG_MODE\n",
    "    )\n",
    "\n",
    "    # 数据划分\n",
    "    dataset_size = len(full_dataset)\n",
    "    val_size = int(VAL_SPLIT * dataset_size)\n",
    "    train_size = dataset_size - val_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size],\n",
    "                                              generator=torch.Generator().manual_seed(42))\n",
    "    val_dataset.dataset.transforms = get_transform(train=False)\n",
    "\n",
    "    # 数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "    # 初始化模型\n",
    "    model = create_model(num_classes=1)\n",
    "    model.to(device)\n",
    "\n",
    "    # 优化器配置\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=LR, momentum=0.9, weight_decay=0.0005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    # 初始化记录字典\n",
    "    metrics_history = []\n",
    "\n",
    "    # 训练循环\n",
    "    best_f1 = 0\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
    "        val_metrics = evaluate(model, val_loader, device)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(\n",
    "            f\"Validation Metrics: Precision={val_metrics['Micro_Prec']:.4f}, Recall={val_metrics['Micro_Recall']:.4f}, F1={val_metrics['Micro_F1']:.4f}\")\n",
    "\n",
    "        # 保存当前epoch的指标\n",
    "        metrics_history.append({\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train_Loss\": train_loss,\n",
    "            \"Precision\": val_metrics[\"Micro_Prec\"],\n",
    "            \"Recall\": val_metrics[\"Micro_Recall\"],\n",
    "            \"F1\": val_metrics[\"Micro_F1\"]\n",
    "        })\n",
    "\n",
    "        # 保存最佳模型\n",
    "        if val_metrics['Micro_F1'] > best_f1:\n",
    "            best_f1 = val_metrics['Micro_F1']\n",
    "            torch.save(model.state_dict(), \"MVss_best_model.pth\")\n",
    "            print(\"↦ 保存新最佳模型\")\n",
    "\n",
    "    # 最终评估\n",
    "    model.load_state_dict(torch.load(\"MVss_best_model.pth\"))\n",
    "    final_metrics = evaluate(model, val_loader, device)\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\n",
    "        f\"最终评估结果: Precision={final_metrics['Micro_Prec']:.4f}, Recall={final_metrics['Micro_Recall']:.4f}, F1={final_metrics['Micro_F1']:.4f}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # 保存所有指标到CSV\n",
    "    save_metrics_to_csv(metrics_history)\n",
    "\n",
    "\n",
    "def save_metrics_to_csv(metrics_history, filename=\"training_metrics.csv\"):\n",
    "    \"\"\"保存训练过程中的指标到CSV文件\"\"\"\n",
    "    df = pd.DataFrame(metrics_history)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Training metrics saved to {filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e75880080bfc9ca5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
